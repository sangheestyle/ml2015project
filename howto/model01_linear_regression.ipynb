{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First model\n",
    "\n",
    "Here is the first model by our own. In this note, you can explorer how read data, train model, make prediction, and save it into submission form.\n",
    "\n",
    "## Load train, test, questions data from pklz\n",
    "\n",
    "First of all, we need to read those three data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import cPickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with gzip.open(\"../data/train.pklz\", \"rb\") as train_file:\n",
    "    train_set = pickle.load(train_file)\n",
    "\n",
    "with gzip.open(\"../data/test.pklz\", \"rb\") as test_file:\n",
    "    test_set = pickle.load(test_file)\n",
    "\n",
    "with gzip.open(\"../data/questions.pklz\", \"rb\") as questions_file:\n",
    "    questions = pickle.load(questions_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look the loaded data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set:  28494\n",
      "test_set:  4749\n",
      "questions:  7949\n"
     ]
    }
   ],
   "source": [
    "print \"train_set: \", len(train_set)\n",
    "print \"test_set: \", len(test_set)\n",
    "print \"questions: \", len(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 8, 9, 10, 11]\n",
      "{'answer': 'cole', 'qid': 1, 'uid': 0, 'position': 61.0}\n",
      "['answer', 'qid', 'uid', 'position']\n"
     ]
    }
   ],
   "source": [
    "print sorted(train_set.keys())[:10]\n",
    "print train_set[1]\n",
    "print train_set[1].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 14, 21, 28, 35, 42, 49, 56, 63, 70]\n",
      "{'qid': 1, 'uid': 6}\n",
      "['qid', 'uid']\n"
     ]
    }
   ],
   "source": [
    "print sorted(test_set.keys())[:10]\n",
    "print test_set[7]\n",
    "print test_set[7].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 5, 6, 11, 19, 35, 36, 42, 44]\n",
      "{'answer': 'thomas cole', 'category': 'Fine Arts', 'group': 'test', 'pos_token': {0: '', 1: 'painters', 2: 'indulgence', 4: 'visual', 5: 'fantasy', 7: 'appreciation', 9: 'different', 10: 'historic', 11: 'architectural', 12: 'styles', 15: 'seen', 18: '1840', 19: 'architects', 20: 'dream', 23: 'series', 25: 'paintings', 28: 'last', 31: 'mohicans', 33: 'made', 35: 'three', 36: 'year', 37: 'trip', 39: 'europe', 41: '1829', 45: 'better', 46: 'known', 49: 'trip', 50: 'four', 51: 'years', 52: 'earlier', 56: 'journeyed', 59: 'hudson', 60: 'river', 63: 'catskill', 64: 'mountains', 65: 'ftp', 66: 'name', 68: 'this_painter', 71: 'oxbow', 74: 'voyage', 76: 'life', 77: 'series'}, 'question': \"This painter's indulgence of visual fantasy, and appreciation of different historic architectural styles can be seen in his 1840 Architect's Dream. After a series of paintings on The Last of the Mohicans, he made a three year trip to Europe in 1829, but he is better known for a trip four years earlier in which he journeyed up the Hudson River to the Catskill Mountains. FTP, name this painter of The Oxbow and The Voyage of Life series.\"}\n",
      "['answer', 'category', 'group', 'pos_token', 'question']\n"
     ]
    }
   ],
   "source": [
    "print sorted(questions.keys())[:10]\n",
    "print questions[1]\n",
    "print questions[1].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make training set\n",
    "\n",
    "For training model, we might need to make feature and lable pair. In this case, we will use only uid, qid, and position for feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = []\n",
    "Y_train = []\n",
    "\n",
    "for key in train_set:\n",
    "    # We only care about positive case at this time\n",
    "    if train_set[key]['position'] < 0:\n",
    "        continue\n",
    "    uid = train_set[key]['uid']\n",
    "    qid = train_set[key]['qid']\n",
    "    pos = train_set[key]['position']\n",
    "    q_length = max(questions[qid]['pos_token'].keys())\n",
    "    feat = [uid, qid, q_length]\n",
    "    X_train.append(feat)\n",
    "    Y_train.append([pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20819\n",
      "20819\n"
     ]
    }
   ],
   "source": [
    "print len(X_train)\n",
    "print len(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 77] [61.0]\n"
     ]
    }
   ],
   "source": [
    "print X_train[0], Y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It means that user 0 tried to solve question number 1 which has 77 tokens for question and he or she answered at 61st token.\n",
    "\n",
    "## Train model and make predictions\n",
    "\n",
    "Let's train model and make predictions. We will use simple Linear Regression at this moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make test set for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test = []\n",
    "test_id = []\n",
    "\n",
    "for key in test_set:\n",
    "    test_id.append(key)\n",
    "    uid = test_set[key]['uid']\n",
    "    qid = test_set[key]['qid']\n",
    "    q_length = max(questions[qid]['pos_token'].keys())\n",
    "    feat = [uid, qid, q_length]\n",
    "    X_test.append(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4749\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[7, 55.969826511813125],\n",
       " [14, 53.595157324938121],\n",
       " [21, 54.428857298633709],\n",
       " [28, 44.809868026370609],\n",
       " [35, 71.263467403313086]]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "predictions = sorted([[id, predictions[index][0]] for index, id in enumerate(test_id)])\n",
    "print len(predictions)\n",
    "predictions[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is 4749 predictions.\n",
    "\n",
    "## Writing submission.\n",
    "\n",
    "OK, let's writing submission into guess.csv file. In the given submission form, we realized that we need to put header. So, we will insert header at the first of predictions, and then make it as a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "predictions.insert(0,[\"id\", \"position\"])\n",
    "with open('guess.csv', 'wb') as fp:\n",
    "    writer = csv.writer(fp, delimiter=',')\n",
    "    writer.writerows(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All right. Let's submit!\n",
    "\n",
    "And... we got... 5th ranked. It's worse than the first submission. Let's think about why.\n",
    "\n",
    "**5 \tnew \tCU_K-ml_Stars \t97.07613  1 \tSun, 05 Apr 2015 23:15:52**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
