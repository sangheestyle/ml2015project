{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model09: refactoring more for _feat_avg_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Functions\n",
    "\n",
    "There have four different functions.\n",
    "\n",
    "* Data reader: Read data from file.\n",
    "* Feature functions(private): Functions which extract features are placed in here. It means that if you make a specific feature function, you can add the one into here.\n",
    "* Feature function(public): We can use only this function for feature extraction.\n",
    "* Utility functions: All the funtions except functions which are mentioned in above should be placed in here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "from os import path\n",
    "from collections import defaultdict\n",
    "from numpy import sign\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Load buzz data as a dictionary.\n",
    "You can give parameter for data so that you will get what you need only.\n",
    "\"\"\"\n",
    "def load_buzz(root='../data', data=['train', 'test', 'questions'], format='pklz'):\n",
    "    buzz_data = {}\n",
    "    for ii in data:\n",
    "        file_path = path.join(root, ii + \".\" + format)\n",
    "        with gzip.open(file_path, \"rb\") as fp:\n",
    "          buzz_data[ii] = pickle.load(fp)\n",
    "        \n",
    "    return buzz_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature functions(private)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy import sign, abs\n",
    "\n",
    "\n",
    "def _feat_basic(bd, group):\n",
    "    X = []\n",
    "    for item in bd[group].items():\n",
    "        qid = item[1]['qid']\n",
    "        q = bd['questions'][qid]\n",
    "        item[1]['q_length'] = max(q['pos_token'].keys())\n",
    "        item[1]['category'] = q['category'].lower()\n",
    "        item[1]['answer'] = q['answer'].lower()\n",
    "        X.append(item[1])\n",
    "        \n",
    "    return X\n",
    "        \n",
    "        \n",
    "def _feat_sign_val(data):\n",
    "    for item in data:\n",
    "        item['sign_val'] = sign(item['position'])\n",
    "\n",
    "\n",
    "def _get_avg_pos(data, sign_val=None):\n",
    "    unwanted_index = []\n",
    "    pos_uid = defaultdict(list)\n",
    "    pos_qid = defaultdict(list)\n",
    "    \n",
    "    for index, key in enumerate(data):\n",
    "        if sign_val and sign(data[key]['position']) != sign_val:\n",
    "            unwanted_index.append(index)\n",
    "        else:\n",
    "            pos_uid[data[key]['uid']].append(data[key]['position'])\n",
    "            pos_qid[data[key]['qid']].append(data[key]['position'])\n",
    "\n",
    "    avg_pos_uid = {}\n",
    "    avg_pos_qid = {}\n",
    "    \n",
    "    if not sign_val:\n",
    "        sign_val = 1\n",
    "\n",
    "    for key in pos_uid:\n",
    "        pos = abs(pos_uid[key])\n",
    "        avg_pos_uid[key] = sign_val * (sum(pos) / len(pos))\n",
    "\n",
    "    for key in pos_qid:\n",
    "        pos = abs(pos_qid[key])\n",
    "        avg_pos_qid[key] = sign_val * (sum(pos) / len(pos))\n",
    "    \n",
    "    return avg_pos_uid, avg_pos_qid, unwanted_index\n",
    "\n",
    "        \n",
    "def _feat_avg_pos(data, bd, group, sign_val):\n",
    "    avg_pos_uid, avg_pos_qid, unwanted_index = _get_avg_pos(bd['train'], sign_val=sign_val)\n",
    "    \n",
    "    if group == 'train':\n",
    "        for index in sorted(unwanted_index, reverse=True):\n",
    "            del data[index]\n",
    "    \n",
    "    for item in data:\n",
    "        if item['uid'] in avg_pos_uid:\n",
    "            item['avg_pos_uid'] = avg_pos_uid[item['uid']]\n",
    "        else:\n",
    "            vals = avg_pos_uid.values()\n",
    "            item['avg_pos_uid'] = sum(vals) / float(len(vals))\n",
    "              \n",
    "        if item['qid'] in avg_pos_qid:\n",
    "            item['avg_pos_qid'] = avg_pos_qid[item['qid']]\n",
    "        else:\n",
    "            vals = avg_pos_qid.values()\n",
    "            item['avg_pos_qid'] = sum(vals) / float(len(vals))\n",
    "        \n",
    "        # Response position can be longer than length of question\n",
    "        if item['avg_pos_uid'] > item['q_length']:\n",
    "            item['avg_pos_uid'] = item['q_length']\n",
    "        \n",
    "        if item['avg_pos_qid'] > item['q_length']:\n",
    "            item['avg_pos_qid'] = item['q_length']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature function(public)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def featurize(bd, group, sign_val=None, extra=None):\n",
    "    # Basic features\n",
    "    # qid(string), uid(string), position(float)\n",
    "    # answer'(string), 'potistion'(float), 'qid'(string), 'uid'(string)\n",
    "    X = _feat_basic(bd, group=group)\n",
    "    \n",
    "    # Some extra features\n",
    "    if extra:\n",
    "        for func_name in extra:\n",
    "            func_name = '_feat_' + func_name\n",
    "            if func_name in ['_feat_avg_pos']:\n",
    "                globals()[func_name](X, bd, group=group, sign_val=sign_val)\n",
    "            else:\n",
    "                globals()[func_name](X)\n",
    "    \n",
    "    if group == 'train':\n",
    "        y = []\n",
    "        for item in X:\n",
    "            y.append(item['position'])\n",
    "            del item['position']\n",
    "\n",
    "        return X, y\n",
    "    elif group == 'test':\n",
    "        return X\n",
    "    else:\n",
    "        raise ValueError(group, 'is not the proper type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "def select(data, keys):\n",
    "    unwanted = data[0].keys() - keys\n",
    "    for item in data:\n",
    "        for unwanted_key in unwanted:\n",
    "            del item[unwanted_key]\n",
    "    return data\n",
    "\n",
    "\n",
    "def write_result(test_set, predictions, file_name='guess.csv'):\n",
    "    predictions = sorted([[id, predictions[index]] for index, id in enumerate(test_set.keys())])\n",
    "    predictions.insert(0,[\"id\", \"position\"])\n",
    "    with open(file_name, \"w\") as fp:\n",
    "        writer = csv.writer(fp, delimiter=',')\n",
    "        writer.writerows(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Linear Cross validation RMSE scores:\n",
      "LinearRegression 82.8796245613\n",
      "Ridge 85.3747383716\n",
      "Lasso 84.7536490473\n",
      "ElasticNet 84.9247541352\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "from sklearn import linear_model\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import math\n",
    "from numpy import abs, sqrt\n",
    "\n",
    "\n",
    "regression_keys = ['category', 'q_length', 'qid', 'uid', 'answer', 'avg_pos_qid', 'avg_pos_pid']\n",
    "X_train, y_train = featurize(load_buzz(), group='train', sign_val=None, extra=['sign_val', 'avg_pos'])\n",
    "X_train = select(X_train, regression_keys)\n",
    "\n",
    "vec = DictVectorizer()\n",
    "X_train = vec.fit_transform(X_train)\n",
    "\n",
    "regressor_names = \"\"\"\n",
    "LinearRegression\n",
    "Ridge\n",
    "Lasso\n",
    "ElasticNet\n",
    "\"\"\"\n",
    "print (\"=== Linear Cross validation RMSE scores:\")\n",
    "for regressor in regressor_names.split():\n",
    "    scores = cross_val_score(getattr(linear_model, regressor)(),\n",
    "                             X_train, y_train,\n",
    "                             cv=10,\n",
    "                             scoring='mean_squared_error',\n",
    "                             n_jobs=multiprocessing.cpu_count()-1\n",
    "                            )\n",
    "    print (regressor, sqrt(abs(scores)).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regression_keys = ['category', 'q_length', 'qid', 'uid', 'answer', 'avg_pos_qid', 'avg_pos_pid']\n",
    "X_train, y_train = featurize(load_buzz(), group='train', sign_val=None, extra=['avg_pos'])\n",
    "X_train = select(X_train, regression_keys)\n",
    "X_test = featurize(load_buzz(), group='test', sign_val=None, extra=['avg_pos'])\n",
    "X_test = select(X_test, regression_keys)\n",
    "\n",
    "vec = DictVectorizer()\n",
    "vec.fit(X_train + X_test)\n",
    "X_train = vec.transform(X_train)\n",
    "X_test = vec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LassoCV(alphas=None, copy_X=True, cv=None, eps=0.001, fit_intercept=True,\n",
       "    max_iter=1000, n_alphas=100, n_jobs=1, normalize=False, positive=False,\n",
       "    precompute='auto', random_state=None, selection='cyclic', tol=0.0001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = linear_model.LassoCV()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.00000000e+00   0.00000000e+00  -0.00000000e+00 ...,   0.00000000e+00\n",
      "   4.28043156e-05  -1.87619270e-02]\n",
      "146.866398809\n"
     ]
    }
   ],
   "source": [
    "print(regressor.coef_)\n",
    "print(regressor.alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "write_result(bd['test'], predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This submissions scores 84.32000 in Kaggle."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
