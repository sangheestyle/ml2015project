{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model 04 linear_model with dictVectorizer\n",
    "\n",
    "Using RMSE\n",
    "\n",
    "## Load train, test, questions data from pklz\n",
    "\n",
    "First of all, we need to read those three data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import cPickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with gzip.open(\"../data/train.pklz\", \"rb\") as train_file:\n",
    "    train_set = pickle.load(train_file)\n",
    "\n",
    "with gzip.open(\"../data/test.pklz\", \"rb\") as test_file:\n",
    "    test_set = pickle.load(test_file)\n",
    "\n",
    "with gzip.open(\"../data/questions.pklz\", \"rb\") as questions_file:\n",
    "    questions = pickle.load(questions_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make training set\n",
    "\n",
    "For training model, we might need to make feature and lable pair. In this case, we will use only uid, qid, and position for feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': 'cole', 'qid': 1, 'uid': 0, 'position': 61.0}\n",
      "['answer', 'category', 'group', 'pos_token', 'question']\n"
     ]
    }
   ],
   "source": [
    "print train_set[1]\n",
    "print questions[1].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n",
    "for key in train_set:\n",
    "    # We only care about positive case at this time\n",
    "    #if train_set[key]['position'] < 0:\n",
    "    #    continue\n",
    "    uid = train_set[key]['uid']\n",
    "    qid = train_set[key]['qid']\n",
    "    pos = train_set[key]['position']\n",
    "    q_length = max(questions[qid]['pos_token'].keys())\n",
    "    category = questions[qid]['category'].lower()\n",
    "    answer = questions[qid]['answer'].lower()\n",
    "    feat = {\"uid\": str(uid), \"qid\": str(qid), \"q_length\": q_length, \"category\": category, \"answer\": answer}\n",
    "    X.append(feat)\n",
    "    Y.append([pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28494\n",
      "28494\n",
      "{'q_length': 77, 'qid': '1', 'category': 'fine arts', 'answer': 'thomas cole', 'uid': '0'} [61.0]\n"
     ]
    }
   ],
   "source": [
    "print len(X)\n",
    "print len(Y)\n",
    "print X[0], Y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It means that user 0 tried to solve question number 1 which has 77 tokens for question and he or she answered at 61st token.\n",
    "\n",
    "## Train model and make predictions\n",
    "\n",
    "Let's train model and make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "\n",
    "vec = DictVectorizer()\n",
    "X = vec.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Cross validation RMSE scores: 82.1830583745\n",
      "[ 76.67270464  84.86393907  77.6004619   72.8021877   76.24757558\n",
      "  77.65462341  80.35628102  94.48375011  97.37825476  83.77080556]\n",
      "Ridge Cross validation RMSE scores: 81.5163799117\n",
      "[ 75.42551662  84.36449222  76.78385805  72.27574686  75.59057276\n",
      "  76.94214904  79.64612587  93.98620172  96.90823254  83.24090344]\n",
      "Lasso Cross validation RMSE scores: 84.8407993557\n",
      "[  77.81940559   89.31984484   79.45613965   73.92431074   77.7030486\n",
      "   80.77462146   83.03076112   98.11867225  102.51332651   85.74786278]\n",
      "ElasticNet Cross validation RMSE scores: 85.0222606404\n",
      "[  77.67035781   89.52297457   79.89587485   74.34862438   77.93037888\n",
      "   80.96532162   83.09002602   98.34951419  102.64014747   85.8093866 ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "import math\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split (X, Y)\n",
    "\n",
    "regressor = LinearRegression()\n",
    "scores = cross_val_score(regressor, X, Y, cv=10, scoring= 'mean_squared_error')\n",
    "# Flip the sign of MSE and take sqrt of that values.\n",
    "for ii in xrange(len(scores)):\n",
    "    scores[ii] = math.sqrt(-1*scores[ii])\n",
    "print 'Linear Cross validation RMSE scores:', scores.mean()\n",
    "print scores\n",
    "\n",
    "regressor = Ridge()\n",
    "scores = cross_val_score(regressor, X, Y, cv=10, scoring= 'mean_squared_error')\n",
    "# Flip the sign of MSE and take sqrt of that values.\n",
    "for ii in xrange(len(scores)):\n",
    "    scores[ii] = math.sqrt(-1*scores[ii])\n",
    "print 'Ridge Cross validation RMSE scores:', scores.mean()\n",
    "print scores\n",
    "\n",
    "regressor = Lasso()\n",
    "scores = cross_val_score(regressor, X, Y, cv=10, scoring= 'mean_squared_error')\n",
    "# Flip the sign of MSE and take sqrt of that values.\n",
    "for ii in xrange(len(scores)):\n",
    "    scores[ii] = math.sqrt(-1*scores[ii])\n",
    "print 'Lasso Cross validation RMSE scores:', scores.mean()\n",
    "print scores\n",
    "\n",
    "regressor = ElasticNet()\n",
    "scores = cross_val_score(regressor, X, Y, cv=10, scoring= 'mean_squared_error')\n",
    "# Flip the sign of MSE and take sqrt of that values.\n",
    "for ii in xrange(len(scores)):\n",
    "    scores[ii] = math.sqrt(-1*scores[ii])\n",
    "print 'ElasticNet Cross validation RMSE scores:', scores.mean()\n",
    "print scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{1: 2}, {2: 3}]\n",
      "[{3: 2}, {4: 3}]\n"
     ]
    }
   ],
   "source": [
    "a = [{1: 2}, {2: 3}]\n",
    "b = [{3: 2}, {4: 3}]\n",
    "c = a + b\n",
    "print c[:len(a)]\n",
    "print c[len(a):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before transform:  4749\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "Y_train = []\n",
    "\n",
    "for key in train_set:\n",
    "    # We only care about positive case at this time\n",
    "    #if train_set[key]['position'] < 0:\n",
    "    #    continue\n",
    "    uid = train_set[key]['uid']\n",
    "    qid = train_set[key]['qid']\n",
    "    pos = train_set[key]['position']\n",
    "    q_length = max(questions[qid]['pos_token'].keys())\n",
    "    category = questions[qid]['category'].lower()\n",
    "    answer = questions[qid]['answer'].lower()\n",
    "    feat = {\"uid\": str(uid), \"qid\": str(qid), \"q_length\": q_length, \"category\": category, \"answer\": answer}\n",
    "    X_train.append(feat)\n",
    "    Y_train.append(pos)\n",
    "\n",
    "X_test = []\n",
    "Y_test = []\n",
    "\n",
    "for key in test_set:\n",
    "    uid = test_set[key]['uid']\n",
    "    qid = test_set[key]['qid']\n",
    "    q_length = max(questions[qid]['pos_token'].keys())\n",
    "    category = questions[qid]['category'].lower()\n",
    "    answer = questions[qid]['answer'].lower()\n",
    "    feat = {\"uid\": str(uid), \"qid\": str(qid), \"q_length\": q_length, \"category\": category, \"answer\": answer}\n",
    "    X_test.append(feat)\n",
    "    Y_test.append(key)\n",
    "\n",
    "print \"Before transform: \", len(X_test)\n",
    "X_train_length = len(X_train)\n",
    "X = vec.fit_transform(X_train + X_test)\n",
    "X_train = X[:X_train_length]\n",
    "X_test = X[X_train_length:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# regressor = LinearRegression()\n",
    "regressor = Ridge()\n",
    "regressor.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4749\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[7, 34.876806438006554],\n",
       " [14, 55.506806653610681],\n",
       " [21, 36.62606574100618],\n",
       " [28, 24.247734632069555],\n",
       " [35, 74.999528288463722]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = regressor.predict(X_test)\n",
    "predictions = sorted([[id, predictions[index]] for index, id in enumerate(Y_test)])\n",
    "print len(predictions)\n",
    "predictions[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is 4749 predictions.\n",
    "\n",
    "## Writing submission.\n",
    "\n",
    "OK, let's writing submission into guess.csv file. In the given submission form, we realized that we need to put header. So, we will insert header at the first of predictions, and then make it as a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "predictions.insert(0,[\"id\", \"position\"])\n",
    "with open('guess.csv', 'wb') as fp:\n",
    "    writer = csv.writer(fp, delimiter=',')\n",
    "    writer.writerows(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All right. Let's submit!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
